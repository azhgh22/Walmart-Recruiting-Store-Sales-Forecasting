# შესავალი

მოცემული პროექტი ეფუძნება **Walmart Recruiting - Store Sales Forecasting**, რომლის მიზანია Walmart-ის მაღაზიების გაყიდვების ზუსტი პროგნოზირება.

პროექტზე მუშაობისას ჩვენ გამოვიკვლიეთ და გავტესტეთ დროითი მწკრივების პროგნოზირებისთვის არსებული მრავალი ცნობილი მეთოდი. მათ შორის:

*   **კლასიკური სტატისტიკური მოდელები:** ARIMA, SARIMA, SARIMAX.
*   **ხეზე დაფუძნებული მოდელები:** XGBoost, LightGBM.
*   **Deep Learning მოდელები დროითი მწკრივებისთვის:** PathTST, N-BEATS, TFT, DLinear.

არსებული მოდელების ტესტირების პარალელურად, ჩვენ შევიმუშავეთ რამდენიმე მოდელის გაერთიანების (ensembling) იდეები და შევქმენით ჩვენი საკუთარი, `group_stat` მოდელები, რომელთა მთავარი პრინციპიც რამდენიმე განსხვავებული მიდგომის გაერთიანებაა. ასევე, შეიქმნა მათი რამდენიმე გაუმჯობესებული ვერსია.

თითოეული მიდგომისა და მოდელის შესახებ დეტალურად მომდევნო სექციებში ვისაუბრებთ.

# EDA (მონაცემთა კვლევითი ანალიზი)

მონაცემთა კვლევითი ანალიზის (EDA) პროცესი დეტალურად არის წარმოდგენილი `notebooks/01_eda.ipynb` ფაილში. ანალიზის შედეგად რამდენიმე მნიშვნელოვანი პატერნი და თვისება გამოვლინდა:

*   **ტრენდი და სეზონურობა:** მონაცემებს არ გააჩნია გამოკვეთილი გრძელვადიანი ტრენდი (მაგალითად, გაყიდვების ზრდა ან კლება წლიდან წლამდე). თუმცა, ნათლად ჩანს ძლიერი **სეზონურობა** — გაყიდვების გრაფიკი ყოველწლიურად თითქმის იდენტურ ფორმას იმეორებს.

*   **დეპარტამენტების მსგავსება მაღაზიებს შორის:** აღმოჩნდა, რომ კონკრეტული დეპარტამენტის გაყიდვების გრაფიკს სხვადასხვა მაღაზიაში ძალიან მსგავსი ფორმა აქვს. მაგალითად, სათამაშოების დეპარტამენტის გაყიდვები ყველა მაღაზიაში ზამთარში აღწევს პიკს. მთავარი განსხვავება მხოლოდ გაყიდვების მოცულობაშია, რაც, სავარაუდოდ, მაღაზიის ზომით ან რეგიონის მოსახლეობის რაოდენობით არის განპირობებული. ფაქტობრივად, ფუნქციის სახე იდენტურია და მხოლოდ კონსტანტით (`offset`) არის გადაადგილებული.

*   **მაღაზიების საშუალო გაყიდვების მსგავსება:** მსგავსი პატერნი შეინიშნება ცალკეული მაღაზიების საშუალო შემოსავლიანობაშიც. თითქმის ყველა მაღაზიის გაყიდვები პიკს აღწევს საახალწლო პერიოდში, ხოლო სხვა დროს მსგავს დონეზე ნარჩუნდება.

*   **ავტოკორელაცია და Lag-მახასიათებლები:** ავტოკორელაციის ფუნქციის ანალიზმა აჩვენა, რომ მიმდინარე კვირის გაყიდვები მნიშვნელოვნად არის დამოკიდებული წინა 2, 3 და 4 კვირის მონაცემებზე (მოკლევადიანი დამოკიდებულება), ასევე წინა წლის იმავე კვირის გაყიდვებზე (გრძელვადიანი, სეზონური დამოკიდებულება). ეს გვაძლევს იმის საფუძველს, რომ მოდელისთვის შევქმნათ როგორც მოკლევადიანი (`lag`), ასევე გრძელვადიანი მახასიათებლები. მაგალითად, მნიშვნელოვანი მახასიათებელი შეიძლება იყოს წლის კონკრეტულ კვირაში (ვთქვათ, მე-5 კვირას) გაყიდვების საშუალო მაჩვენებელი წინა წლების განმავლობაში.

ამ დაკვირვებებმა გვიბიძგა მთავარი იდეისკენ: იმის მაგივრად, რომ მხოლოდ ისტორიულ საშუალო მაჩვენებლებს დავყრდნობოდით, ჩვენ შეგვიძლია შევქმნათ უფრო დინამიური მახასიათებლები. კერძოდ, ყოველი მონაცემისთვის დავამატოთ ორი ახალი მახასიათებელი (feature):

1.  **`dept_predicted_sales`**: პროგნოზი, რომელიც გაკეთებულია მხოლოდ დეპარტამენტის დონეზე (ყველა მაღაზიის მონაცემის აგრეგირებით).
2.  **`store_predicted_sales`**: პროგნოზი, რომელიც გაკეთებულია მხოლოდ მაღაზიის დონეზე (ყველა დეპარტამენტის მონაცემის აგრეგირებით).

ამ მახასიათებლების მისაღებად, ჩვენ ჯერ ცალკეული მოდელებით ვასწავლით და ვაპროგნოზირებთ `store_avg` და `dept_avg` გაყიდვებს, შემდეგ კი ამ პროგნოზებს, როგორც მძლავრ მახასიათებლებს, ვუმატებთ ჩვენს მთავარ მოდელს. სწორედ ეს მიდგომა უდევს საფუძვლად ჩვენს `group_stat` მოდელს.

# მოდელების მიმოხილვა

ამ სექციაში განვიხილავთ ყველა იმ მოდელს, რომელიც პროექტის ფარგლებში გავტესტეთ, დაწყებული კლასიკური სტატისტიკური მეთოდებიდან, დასრულებული თანამედროვე Deep Learning არქიტექტურებით.

## სტატისტიკური მოდელები

### ARIMA
ARIMA დროითი მწკრივების ანალიზის ერთ-ერთი ყველაზე მარტივი და კლასიკური სტატისტიკური მოდელია. მისი შედეგები ვალიდაციის მონაცემებზე იყო **4195.88**, ხოლო სატრენინგო მონაცემებზე — **2660.10**.

ეს საკმაოდ სუსტი შედეგია, რაც მოსალოდნელიც იყო, რადგან მოდელს რამდენიმე მნიშვნელოვანი ნაკლი აქვს:
*   **წრფივობა:** ის ეფუძნება წრფივ დაშვებებს, ჩვენი მონაცემების სტრუქტურა კი აშკარად არაწრფივია.
*   **გარე მახასიათებლების იგნორირება:** მოდელი არ ითვალისწინებს დამატებით მახასიათებლებს(`features`), როგორიცაა სადღესასწაულო დღეები, ტემპერატურა და ა.შ.

### SARIMA
SARIMA წარმოადგენს ARIMA მოდელის გაუმჯობესებულ ვერსიას, რომელიც დამატებით ითვალისწინებს **სეზონურობას**. რადგან ჩვენს მონაცემებს წლიური სეზონურობა აქვთ, ამ მოდელმა უკეთ უნდა იმუშავოს.

მოდელის დასწავლის დრო (`runtime`) ძალიან დიდი აღმოჩნდა, ამიტომ გადავწყვიტეთ, ექსპერიმენტი ჩაგვეტარებინა მონაცემთა ნაწილზე (`sampling`) — შემთხვევითად შევარჩიეთ რამდენიმე `store/dept` წყვილი. შედეგები დასემპლილ მონაცემებზე ასეთი იყო: **Train WMAE: 21910.49**, **Valid WMAE: 22466.55**.

მიუხედავად იმისა, რომ მოდელი თეორიულად უფრო მძლავრია, სრულ მონაცემთა ბაზაზე მისი გაშვება და პროგნოზის გაკეთება გამოთვლითი სირთულის გამო პრაქტიკულად შეუძლებელია.

### SARIMAX
იგივე დასემპლილ მონაცემებზე გავტესტეთ SARIMAX მოდელიც, რომელიც SARIMA-ს საშუალებას აძლევს, გაითვალისწინოს გარე მახასიათებლები (`eXogenous features`). შედეგები ასეთი იყო: **Train WMAE: 578148.08**, **Valid WMAE: 308131.33**.

როგორც ვხედავთ, შედეგი მნიშვნელოვნად გაუარესდა SARIMA-სთან შედარებითაც კი. ეს ნიშნავს, რომ დამატებითი მახასიათებლების ჩართვამ მოდელის ხარისხი შეამცირა. ამის სავარაუდო მიზეზებია:

*   SARIMAX მოდელი შეიძლება ზედმეტად ხისტი იყოს მონაცემებში არსებული რთული ურთიერთდამოკიდებულებების აღსაქმელად.
*   დამატებითმა მახასიათებლებმა შესაძლოა „ხმაური“ შეიტანა მოდელში, თუ ისინი არასწორად იქნა გამოყენებული.
*   შერჩეული მონაცემების სიმცირემ (სემპლინგის გამო) შესაძლოა გააძლიერა გადაჭარბებული მორგების (overfitting) ეფექტი, როდესაც მოდელს მეტი ცვლადი დაემატა.

შედეგები შეგიძლიათ ნახოთ: `notebooks/02_linear_models.ipynb`.

## ხეზე დაფუძნებული მოდელები

### XGBoost

პროექტში გავტესტეთ XGBoost, რომელიც ერთ-ერთი ყველაზე მძლავრი მოდელია. აღსანიშნავია, რომ LightGBM-ს მსგავსი პრინციპი აქვს, თუმცა ის უფრო ეფექტურია დიდ მონაცემთა ბაზებზე. ამ ეტაპზე ფოკუსირება XGBoost-ზე გავაკეთეთ.

XGBoost-ის მთავარი ნაკლი ისაა, რომ ის ბუნებრივად არ ითვალისწინებს დროითი მწკრივის სტრუქტურას, ანუ წარსული მოვლენების პირდაპირ დამოკიდებულებას მომავალზე. თუმცა, ამის კომპენსირება შესაძლებელია სწორი მახასიათებლების ინჟინერიით (`feature engineering`).

ჩვენ დავამატეთ შემდეგი მახასიათებლები:
*   წელიწადის კვირის ნომერი
*   სადღესასწაულო დღის ინდიკატორი
*   დრო, რომელიც დარჩა მომდევნო დღესასწაულამდე
*   ფურიეს გარდაქმნის მახასიათებლები (სეზონურობის აღსაქმელად)

ამ მახასიათებლებით მივიღეთ შემდეგი შედეგი:
-   **Train WMAE:** 1632.75
-   **Valid WMAE:** 2893.66

ეს შედეგი მნიშვნელოვნად აღემატება სტატისტიკური მოდელებისას.

### XGBoost ავტორეგრესიული მიდგომით

შემდეგ ვცადეთ XGBoost-ის ავტორეგრესიული მოდელირება. ამ მიდგომისას, მახასიათებლებად დავამატეთ `lag`-ები: წინა 2, 3 და 51-ე კვირის გაყიდვების მონაცემები. პროგნოზირების პროცესში, ეს `lag`-ები დინამიურად ივსებოდა ჩვენივე წინა პროგნოზებით.

შედეგები ასეთი იყო:
-   **Train WMAE:** 3001.25
-   **Valid WMAE:** 3232.62

როგორც ვხედავთ, შედეგი **გაუარესდა**. ეს იმას მიუთითებს, რომ მოდელის მიერ ერთხელ დაშვებული შეცდომა (არასწორი პროგნოზი) შემდეგ ნაბიჯზე გადადის და `lag`-ის სახით ახალ შეცდომას იწვევს, რაც საბოლოოდ აკუმულირდება და აუარესებს საერთო ხარისხს. განსაკუთრებით პრობლემურია ის `store/dept` წყვილები, რომლებზეც ცოტა მონაცემი გვაქვს, რადგან მათზე არაზუსტი პროგნოზი გარდაუვალია და ამ შეცდომაზე დაყრდნობა მოდელს არასწორი მიმართულებით წაიყვანს.

## ნეირონული ქსელები (Deep Learning Models)

პროექტის ფარგლებში, ასევე გამოვცადეთ დროითი მწკრივებისთვის განკუთვნილი ოთხი ნეირონული ქსელის არქიტექტურა. თითოეული მოდელისთვის ჩატარდა ჰიპერპარამეტრების ოპტიმიზაცია (tuning), რის შედეგადაც მივიღეთ საინტერესო შედეგები.

ქვემოთ მოცემულია გამოყენებული მოდელების ძირითადი ჰიპერპარამეტრები:

| მოდელი | მნიშვნელოვანი ჰიპერპარამეტრები |
| :--- | :--- |
| **N-BEATS** | `input_size=52`, `h=53`, `learning_rate=1e-3`, `batch_size=256`, `optimizer=AdamW`, `shared_weights=True` |
| **D-Linear** | `input_size=60`, `h=53`, `learning_rate=1e-2`, `batch_size=512`, `optimizer=Adagrad`, `scaler_type='robust'` |
| **PatchTST** | `input_size=52`, `h=53`, `dropout=0.2`, `batch_size=64`, `activation='relu'` |
| **TFT** | `input_size=60`, `h=53`, `dropout=0.1`, `max_steps=20*104` |

*შენიშვნა: `h=53` ნიშნავს, რომ მოდელი აპროგნოზირებს მომდევნო 53 კვირის მონაცემებს.*

### შედეგები (ვალიდაციის WMAE)

აღსანიშნავია, რომ გამოყენებული `neuralforecast` ბიბლიოთეკა არ ითვლის სატრენინგო (train) მონაცემებზე შეცდომას, ამიტომ წარმოდგენილია მხოლოდ ვალიდაციის შედეგები.

| მოდელი | ვალიდაციის WMAE |
| :--- | :--- |
| **PatchTST** | **1526.46** |
| **N-BEATS** | 1587.59 |
| **D-Linear** | 1598.11 |
| **TFT** | 1717.15 |

### ანალიზი

როგორც შედეგებიდან ჩანს, საუკეთესო ხარისხი აჩვენა **PatchTST** მოდელმა, რომელმაც ყველა წინა მოდელზე (სტატისტიკურსა და ხეზე დაფუძნებულზე) მნიშვნელოვნად უკეთესი შედეგი დადო. მას მცირედით ჩამორჩებიან N-BEATS და D-Linear, ხოლო TFT-ის შედეგი შედარებით სუსტია.

ყველაზე საინტერესო და, გარკვეულწილად, მოულოდნელი დაკვირვება ისაა, რომ ეს შედეგები მიღწეულია **ყოველგვარი გარე მახასიათებლების (features) გარეშე**. ნეირონულმა ქსელებმა შეძლეს მხოლოდ დროითი მწკრივის ისტორიულ მონაცემებზე დაყრდნობით (univariate approach) აღექვათ რთული სეზონური პატერნები და დამოკიდებულებები. ეს მიუთითებს იმაზე, რომ ამ მონაცემებში საკმარისი ინფორმაციაა მაღალი სიზუსტის პროგნოზის მისაღებად და, შესაძლოა, მხოლოდ წინა გაყიდვების დინამიკის ანალიზითაც შეიძლება კარგი შედეგის მიღწევა.
