{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azhgh22/Walmart-Recruiting-Store-Sales-Forecasting/blob/main/notebooks/n_beats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7f97a322",
      "metadata": {
        "collapsed": true,
        "id": "7f97a322"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import userdata\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "user_name = userdata.get('GITHUB_USERNAME')\n",
        "mail = userdata.get('GITHUB_MAIL')\n",
        "\n",
        "!git config --global user.name \"{user_name}\"\n",
        "!git config --global user.email \"{mail}\"\n",
        "!git clone https://{token}@github.com/azhgh22/Walmart-Recruiting-Store-Sales-Forecasting.git\n",
        "\n",
        "%cd Walmart-Recruiting-Store-Sales-Forecasting\n",
        "\n",
        "from google.colab import userdata\n",
        "! pip install -r ./requirements.txt\n",
        "kaggle_json_path = userdata.get('KAGGLE_JSON_PATH')\n",
        "! ./src/data_loader.sh -f {kaggle_json_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "056809de",
      "metadata": {
        "id": "056809de"
      },
      "outputs": [],
      "source": [
        "# **Torch**\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import torch\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.models import NBEATS\n",
        "from neuralforecast.losses.pytorch import MSE\n",
        "\n",
        "from src.config import *\n",
        "\n",
        "stores = pd.read_csv(STORES_PATH)\n",
        "features = pd.read_csv(FEATURES_PATH)\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "train['Date'] = pd.to_datetime(train.Date)\n",
        "# test['Date'] = pd.to_datetime(test.Date)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.processing import split_data\n",
        "x_train,y_train,x_val,y_val = split_data(train)"
      ],
      "metadata": {
        "id": "Fur_h7V8BsSd"
      },
      "id": "Fur_h7V8BsSd",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Validation**"
      ],
      "metadata": {
        "id": "aHljSUxRVskI"
      },
      "id": "aHljSUxRVskI"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomNBEATS(NBEATS):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
        "\n",
        "    def set_optim(self,optimizer):\n",
        "      self.optimizer = optimizer\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Define your custom optimizer here\n",
        "        optimizer = self.optimizer #torch.optim.AdamW(self.parameters(), lr=1e-3)\n",
        "\n",
        "        # Optional: add scheduler if needed\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
        "\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            # 'lr_scheduler': {\n",
        "            #     'scheduler': scheduler,\n",
        "            #     'interval': 'epoch',\n",
        "            #     'frequency': 1\n",
        "            # }\n",
        "        }"
      ],
      "metadata": {
        "id": "oCYKVYmWyTuj"
      },
      "id": "oCYKVYmWyTuj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class Preprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        x_copy = X.copy()\n",
        "        if 'y' not in x_copy.columns:\n",
        "            x_copy['y'] = 0\n",
        "        x_copy['Date'] = pd.to_datetime(x_copy['Date'])\n",
        "        return x_copy\n"
      ],
      "metadata": {
        "id": "KnmaJP0xpiYw"
      },
      "id": "KnmaJP0xpiYw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NBEATSModel(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,models:list[NBEATS]=None):\n",
        "        if models == None or len(models)==0:\n",
        "          if torch.cuda.is_available():\n",
        "            device = 'gpu'\n",
        "          else:\n",
        "            device = 'cpu'\n",
        "          models = [CustomNBEATS(\n",
        "            input_size=15,\n",
        "            h=48,\n",
        "            max_steps=25 * 104,\n",
        "            batch_size=64,\n",
        "            stack_types=(['identity', 'trend', 'seasonality']),\n",
        "            n_blocks = [1,1,1],\n",
        "            random_seed=42,\n",
        "            accelerator=device,\n",
        "            devices=1,\n",
        "            logger=True,\n",
        "            enable_progress_bar=False,\n",
        "            enable_model_summary=False,\n",
        "        )]\n",
        "        self.nf = NeuralForecast(models=models, freq='W-FRI')\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        df = self.create_data_nbeats(X,y)\n",
        "        df.sort_values(by=['ds'],inplace=True)\n",
        "        self.nf.fit(df)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        preds = self.nf.predict()\n",
        "\n",
        "        real = self.create_data_nbeats(X,X.y)\n",
        "        merged = pd.merge(real, preds, on=['unique_id','ds'],how='left')\n",
        "        # print(merged.shape)\n",
        "        merged.fillna(0,inplace=True)\n",
        "\n",
        "\n",
        "        return merged\n",
        "\n",
        "\n",
        "    def predict(self,X=None):\n",
        "        return self.transform(X)\n",
        "\n",
        "    def create_data_nbeats(self,x:pd.DataFrame,y:pd.DataFrame) -> pd.DataFrame:\n",
        "        df = pd.DataFrame()\n",
        "\n",
        "        df = df.reset_index()\n",
        "        df[\"Date\"] = x.Date\n",
        "        df[\"Store\"] = x.Store\n",
        "        df[\"Dept\"] = x.Dept\n",
        "        df[\"IsHoliday\"] = x.IsHoliday.astype(int)\n",
        "        df.rename(columns={\"Date\": \"ds\"}, inplace=True)\n",
        "        df[\"unique_id\"] = df[\"Store\"].astype(str) + \"_\" + df[\"Dept\"].astype(str)\n",
        "        df[\"y\"] = y.values\n",
        "        df = df[[\"unique_id\", \"ds\", \"y\",'IsHoliday']].copy()\n",
        "        return df"
      ],
      "metadata": {
        "id": "-3Qkm_fnqoOf"
      },
      "id": "-3Qkm_fnqoOf",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import pipe\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocess', Preprocessor()),\n",
        "    ('model', NBEATSModel())\n",
        "])\n",
        "\n",
        "model = pipeline.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "3rOEwdu-BIb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62569715-771e-4f1d-ce7e-ff261bf583a7"
      },
      "id": "3rOEwdu-BIb1",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils import wmae\n",
        "x_val['y'] = y_val\n",
        "preds = model.predict(x_val)\n",
        "wmae(preds['y'],preds['CustomNBEATS'],preds['IsHoliday'])"
      ],
      "metadata": {
        "id": "UVX4eeKzrYLz",
        "outputId": "642b4490-0984-439f-c0f4-22cf03a19f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UVX4eeKzrYLz",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(2462.0331187605916)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grid Search**"
      ],
      "metadata": {
        "id": "akBSMqH4FEdR"
      },
      "id": "akBSMqH4FEdR"
    },
    {
      "cell_type": "code",
      "source": [
        "l = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10]\n",
        "for lr in l:\n",
        "  estim = CustomNBEATS(\n",
        "              input_size=15,\n",
        "              h=48,\n",
        "              max_steps=25 * 104,\n",
        "              batch_size=64,\n",
        "              stack_types=(['identity', 'trend', 'seasonality']+['identity']*8),\n",
        "              n_blocks = [1,1,1]+[1]*8,\n",
        "              random_seed=42,\n",
        "              accelerator='gpu',\n",
        "              devices=1,\n",
        "              logger=True,\n",
        "              enable_progress_bar=False,\n",
        "              enable_model_summary=False,)\n",
        "\n",
        "  estim.set_optim(torch.optim.AdamW(estim.parameters(), lr=1e-3,weight_decay=lr))\n",
        "\n",
        "  estimators = [estim]\n",
        "\n",
        "  pipeline = Pipeline([\n",
        "      ('preprocess', Preprocessor()),\n",
        "      ('model', NBEATSModel(estimators))\n",
        "  ])\n",
        "\n",
        "  model = pipeline.fit(x_train,y_train)\n",
        "  x_val['y'] = y_val\n",
        "  preds = model.predict(x_val)\n",
        "  score = wmae(preds['y'],preds['CustomNBEATS'],preds['IsHoliday'])\n",
        "  print(lr,score)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wS5tEPsEUBp",
        "outputId": "932adf01-7227-419e-9e8b-94c1fb4066f4"
      },
      "id": "9wS5tEPsEUBp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1e-06 2392.3769091145205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1e-05 2392.3769091145205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001 2399.894715793578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001 2427.682577222331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01 2408.8660710503596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 2399.4685652406197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2392.3769091145205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2523.376480050695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 8963.528303510586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estim = CustomNBEATS(\n",
        "            input_size=15,\n",
        "            h=48,\n",
        "            max_steps=25 * 104,\n",
        "            batch_size=64,\n",
        "            stack_types=(['identity', 'trend', 'seasonality']),\n",
        "            n_blocks = [1,1,1],\n",
        "            random_seed=42,\n",
        "            accelerator='gpu',\n",
        "            devices=1,\n",
        "            logger=True,\n",
        "            enable_progress_bar=False,\n",
        "            enable_model_summary=False,)\n",
        "\n",
        "# estim.set_optim(torch.optim.AdamW(estim.parameters(), lr=1e-3,weight_decay=0))\n",
        "\n",
        "estimators = [estim]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocess', Preprocessor()),\n",
        "    ('model', NBEATSModel())\n",
        "])\n",
        "\n",
        "model = pipeline.fit(x_train,y_train)\n",
        "x_val['y'] = y_val\n",
        "preds = model.predict(x_val)\n",
        "score = wmae(preds['y'],preds['CustomNBEATS'],preds['IsHoliday'])\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ4IrpQpTgGz",
        "outputId": "ae21d9d8-066f-4dc0-bbfa-4aa3b72ad4d9"
      },
      "id": "GZ4IrpQpTgGz",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2462.0331187605916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dvV2GVyUSPR",
        "outputId": "a218c921-8574-4149-bbea-d4c0f5f92540"
      },
      "id": "6dvV2GVyUSPR",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazhgh22\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import joblib\n",
        "\n",
        "\n",
        "fin_model = pipeline.fit(train.drop(columns=['Weekly_Sales'].copy()),train['Weekly_Sales'].copy())\n",
        "\n",
        "joblib.dump(fin_model, \"nbeats_run2.pkl\")\n",
        "wandb.init(project=\"Walmart Recruiting - Store Sales Forecasting\", name=\"nbeats:run2\")\n",
        "\n",
        "wandb.config.update({\n",
        "    'score_metric' : 'WMAE',\n",
        "    'score_policy' : {\n",
        "        'weight on holidays' : 5,\n",
        "        'weight on non_holidays' : 1\n",
        "    },\n",
        "    'model' : 'nbeats',\n",
        "    'learning_rate' : 0.001,\n",
        "    'weight_decay' : 0,\n",
        "    'batch_size' : 64,\n",
        "    'max_depth' : 7,\n",
        "    'max_steps' : 25 * 104,\n",
        "    'input_size' : 15,\n",
        "    'horizon': 48,\n",
        "    'architecture' : ['identity', 'trend', 'seasonality'],\n",
        "    'n_blocks' : [1,1,1],\n",
        "    'random_state': 42,\n",
        "    'objective' : 'reg:squarederror',\n",
        "})\n",
        "\n",
        "wandb.log({\n",
        "    'val_wmae': score\n",
        "})\n",
        "\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    name=\"nbeats_run2\",\n",
        "    type=\"model\",\n",
        ")\n",
        "\n",
        "artifact.add_file(\"nbeats_run2.pkl\")\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "vhSq6IHWWaYB",
        "outputId": "536e17bc-6575-4933-a5db-30ce41f6e30f"
      },
      "id": "vhSq6IHWWaYB",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=2600` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Walmart-Recruiting-Store-Sales-Forecasting/wandb/run-20250706_194946-y0hk4rn3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/y0hk4rn3' target=\"_blank\">nbeats:run2</a></strong> to <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/y0hk4rn3' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/y0hk4rn3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_wmae</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_wmae</td><td>2462.03312</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">nbeats:run2</strong> at: <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/y0hk4rn3' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/y0hk4rn3</a><br> View project at: <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250706_194946-y0hk4rn3/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = fin_model.predict(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKcFMh3HYtjl",
        "outputId": "91641c46-314e-4a04-bbc0-f4c3067002ef"
      },
      "id": "dKcFMh3HYtjl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = test.copy()\n",
        "test1['unique_id'] = test1[\"Store\"].astype(str) + \"_\" + test1[\"Dept\"].astype(str)\n",
        "test1['ds'] = pd.to_datetime(test1['Date'])"
      ],
      "metadata": {
        "id": "XwCIxbABnSBV"
      },
      "id": "XwCIxbABnSBV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.merge(test1, pred, on=['unique_id','ds'],how='left')\n",
        "merged['Id'] = test1[\"unique_id\"].astype(str) + \"_\" + test1[\"ds\"].astype(str)\n",
        "merged['Weekly_Sales'] = merged['CustomNBEATS']"
      ],
      "metadata": {
        "id": "XFLxSkmVoGct"
      },
      "id": "XFLxSkmVoGct",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jjBwyFLCos-j"
      },
      "id": "jjBwyFLCos-j"
    },
    {
      "cell_type": "code",
      "source": [
        "merged[['Id','Weekly_Sales']].to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "2ZrMFCYPoVpm"
      },
      "id": "2ZrMFCYPoVpm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}