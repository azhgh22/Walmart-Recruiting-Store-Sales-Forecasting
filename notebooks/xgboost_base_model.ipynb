{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azhgh22/Walmart-Recruiting-Store-Sales-Forecasting/blob/main/notebooks/xgboost_base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3e52d889",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e52d889",
        "outputId": "a7941d42-bea9-49fa-f81e-7f78de24567e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "user_name = userdata.get('GITHUB_USERNAME')\n",
        "mail = userdata.get('GITHUB_MAIL')\n",
        "\n",
        "!git config --global user.name \"{user_name}\"\n",
        "!git config --global user.email \"{mail}\"\n",
        "!git clone https://{token}@github.com/azhgh22/Walmart-Recruiting-Store-Sales-Forecasting.git\n",
        "\n",
        "%cd Walmart-Recruiting-Store-Sales-Forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3cRwSz0PsGw",
        "outputId": "e56c657a-2c35-4b33-b79d-cedb132aa913"
      },
      "id": "u3cRwSz0PsGw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Walmart-Recruiting-Store-Sales-Forecasting'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 196 (delta 90), reused 159 (delta 64), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (196/196), 6.38 MiB | 30.99 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/Walmart-Recruiting-Store-Sales-Forecasting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "!pip install -r requirements.txt\n",
        "kaggle_json_path = userdata.get('KAGGLE_JSON_PATH')\n",
        "! ./src/data_loader.sh -f {kaggle_json_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3sdpsFoP0vh",
        "outputId": "e64cbd0f-9d30-47b4-b690-9d2d7e241a80"
      },
      "id": "K3sdpsFoP0vh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.7.4.5)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1)\n",
            "Collecting onnx (from -r requirements.txt (line 3))\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Collecting dagshub (from -r requirements.txt (line 8))\n",
            "  Downloading dagshub-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mlflow (from -r requirements.txt (line 9))\n",
            "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (4.3.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (4.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Collecting appdirs>=1.4.4 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub->-r requirements.txt (line 8)) (0.28.1)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub->-r requirements.txt (line 8)) (13.9.4)\n",
            "Collecting dacite~=1.6.0 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub->-r requirements.txt (line 8)) (8.5.0)\n",
            "Collecting gql[requests] (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting dataclasses-json (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting treelib>=1.6.4 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading treelib-1.8.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pathvalidate>=3.0.0 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading boto3-1.39.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting semver (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting dagshub-annotation-converter>=0.1.5 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (3.1.1)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.115.13)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.34.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 9)) (1.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub->-r requirements.txt (line 8)) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub->-r requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2)) (4.0.12)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (3.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub->-r requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r requirements.txt (line 9)) (3.2.3)\n",
            "Collecting botocore<1.40.0,>=1.39.1 (from boto3->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading botocore-1.39.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub->-r requirements.txt (line 8)) (1.20.1)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.46.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2)) (5.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub->-r requirements.txt (line 8)) (0.1.2)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub->-r requirements.txt (line 8)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub->-r requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.6.1)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dagshub-0.5.10-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl (33 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading treelib-1.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading boto3-1.39.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.39.1-py3-none-any.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading gql-3.5.3-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: appdirs, treelib, semver, pathvalidate, onnx, mypy-extensions, marshmallow, jmespath, gunicorn, graphql-core, dacite, backoff, typing-inspect, opentelemetry-api, graphql-relay, gql, docker, botocore, alembic, s3transfer, opentelemetry-semantic-conventions, graphene, dataclasses-json, databricks-sdk, dagshub-annotation-converter, opentelemetry-sdk, boto3, mlflow-skinny, dagshub, mlflow\n",
            "Successfully installed alembic-1.16.2 appdirs-1.4.4 backoff-2.2.1 boto3-1.39.1 botocore-1.39.1 dacite-1.6.0 dagshub-0.5.10 dagshub-annotation-converter-0.1.10 databricks-sdk-0.57.0 dataclasses-json-0.6.7 docker-7.1.0 gql-3.5.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 marshmallow-3.26.1 mlflow-3.1.1 mlflow-skinny-3.1.1 mypy-extensions-1.1.0 onnx-1.18.0 opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 pathvalidate-3.3.1 s3transfer-0.13.0 semver-3.0.4 treelib-1.8.0 typing-inspect-0.9.0\n",
            "Setting up Kaggle credentials...\n",
            "Ensuring data directory exists at 'data/'...\n",
            "Downloading data from Kaggle for competition: 'walmart-recruiting-store-sales-forecasting'...\n",
            "Downloading walmart-recruiting-store-sales-forecasting.zip to data\n",
            "  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "100% 2.70M/2.70M [00:00<00:00, 719MB/s]\n",
            "Unzipping files...\n",
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  features.csv.zip\n",
            "  inflating: features.csv            \n",
            "Archive:  sampleSubmission.csv.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Data downloaded and extracted successfully to 'data/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "irVmks2kP-9b"
      },
      "id": "irVmks2kP-9b",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.config import *\n",
        "\n",
        "stores = pd.read_csv(STORES_PATH)\n",
        "features = pd.read_csv(FEATURES_PATH)\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "pzy0BHMtQB2U"
      },
      "id": "pzy0BHMtQB2U",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merge tables and split data**"
      ],
      "metadata": {
        "id": "RG0T-1kbUCFX"
      },
      "id": "RG0T-1kbUCFX"
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train = pd.merge(train,stores,on='Store',how='left').merge(features,how='left',on=['Store','Date','IsHoliday'])"
      ],
      "metadata": {
        "id": "A2pAEl5eQDk6"
      },
      "id": "A2pAEl5eQDk6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.time_series_split import TimeSeriesSplit\n",
        "from src.config import SPLIT_DATE\n",
        "merged_train.Date = pd.to_datetime(merged_train.Date)\n",
        "x_train, x_val = TimeSeriesSplit(SPLIT_DATE).split(merged_train)\n",
        "for i in range(1,3):\n",
        "  x_train[f'shift{i}'] = x_train.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(i)\n",
        "  x_val[f'shift{i}'] = x_val.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(i)\n",
        "\n",
        "y_train = x_train.pop('Weekly_Sales')\n",
        "y_val = x_val.pop('Weekly_Sales')"
      ],
      "metadata": {
        "id": "HqczOQCDQ7cV"
      },
      "id": "HqczOQCDQ7cV",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Time series features**"
      ],
      "metadata": {
        "id": "OHyedVy0rS1b"
      },
      "id": "OHyedVy0rS1b"
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_engineering.time_features import FeatureAdder"
      ],
      "metadata": {
        "id": "ZukYktexrSXk"
      },
      "id": "ZukYktexrSXk",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deal with **NaN** values"
      ],
      "metadata": {
        "id": "y1BiYRuUUkAC"
      },
      "id": "y1BiYRuUUkAC"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "class NaImputer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, strategy='mean'):\n",
        "    self.strategy = strategy\n",
        "    self.imputer = SimpleImputer(strategy=strategy)\n",
        "    self.na_cols = []\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    self.na_cols = [col for col in X.columns if X[col].isna().sum() > 0]\n",
        "    self.imputer.fit(X[self.na_cols])\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    x_copy = X.copy()\n",
        "    x_copy[self.na_cols] = self.imputer.transform(x_copy[self.na_cols])\n",
        "    return x_copy"
      ],
      "metadata": {
        "id": "iSiUpzBFUAGF"
      },
      "id": "iSiUpzBFUAGF",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cat2Num**"
      ],
      "metadata": {
        "id": "6JPO12Wpm7AB"
      },
      "id": "6JPO12Wpm7AB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class Cat2Num(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    x_copy = X.copy()\n",
        "    x_copy.pop('Date')\n",
        "    x_copy.IsHoliday = x_copy.IsHoliday.astype(int)\n",
        "    x_copy.Type = x_copy.Type.astype('category').cat.codes\n",
        "    return x_copy"
      ],
      "metadata": {
        "id": "IYLi_oCim6Mq"
      },
      "id": "IYLi_oCim6Mq",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add lags to data**"
      ],
      "metadata": {
        "id": "as8dAagCTuyC"
      },
      "id": "as8dAagCTuyC"
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "abp_FcN_Rq89"
      },
      "id": "abp_FcN_Rq89",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "3wDfp75CRu6Y",
        "outputId": "f4a37184-af0d-44cb-8352-a645e0e4d81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "id": "3wDfp75CRu6Y",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Store  Dept        Date  IsHoliday\n",
              "0           1     1  2012-11-02      False\n",
              "1           1     1  2012-11-09      False\n",
              "2           1     1  2012-11-16      False\n",
              "3           1     1  2012-11-23       True\n",
              "4           1     1  2012-11-30      False\n",
              "...       ...   ...         ...        ...\n",
              "115059     45    98  2013-06-28      False\n",
              "115060     45    98  2013-07-05      False\n",
              "115061     45    98  2013-07-12      False\n",
              "115062     45    98  2013-07-19      False\n",
              "115063     45    98  2013-07-26      False\n",
              "\n",
              "[115064 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22810de4-a1f9-4264-a9c9-d99580780db3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-02</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-09</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-16</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-23</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2012-11-30</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115059</th>\n",
              "      <td>45</td>\n",
              "      <td>98</td>\n",
              "      <td>2013-06-28</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115060</th>\n",
              "      <td>45</td>\n",
              "      <td>98</td>\n",
              "      <td>2013-07-05</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115061</th>\n",
              "      <td>45</td>\n",
              "      <td>98</td>\n",
              "      <td>2013-07-12</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115062</th>\n",
              "      <td>45</td>\n",
              "      <td>98</td>\n",
              "      <td>2013-07-19</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115063</th>\n",
              "      <td>45</td>\n",
              "      <td>98</td>\n",
              "      <td>2013-07-26</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115064 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22810de4-a1f9-4264-a9c9-d99580780db3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22810de4-a1f9-4264-a9c9-d99580780db3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22810de4-a1f9-4264-a9c9-d99580780db3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a77dff81-4f15-45a8-b476-19c4c3996221\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a77dff81-4f15-45a8-b476-19c4c3996221')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a77dff81-4f15-45a8-b476-19c4c3996221 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_297ba730-25c5-4394-9ba3-c2ab9beb2d0b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_297ba730-25c5-4394-9ba3-c2ab9beb2d0b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_train.columns"
      ],
      "metadata": {
        "id": "GlSoPGduT1KL",
        "outputId": "799029e0-50d0-49ef-b59d-4536d4b15234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GlSoPGduT1KL",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Store', 'Dept', 'IsHoliday', 'Type', 'Size', 'Temperature',\n",
              "       'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
              "       'MarkDown5', 'CPI', 'Unemployment', 'DateDummy', 'shift1', 'shift2',\n",
              "       'Month', 'Year', 'WeekOfYear', 'Is_Christmas', 'Is_SuperBowl',\n",
              "       'Is_LaborDay', 'Is_Thanksgiving', 'Days_until_next_holiday',\n",
              "       'Days_since_last_holiday', 'week_sin', 'week_cos', 'month_sin',\n",
              "       'month_cos', 'Days_until_next_Christmas', 'Days_since_last_Christmas',\n",
              "       'Days_until_next_SuperBowl', 'Days_since_last_SuperBowl',\n",
              "       'Days_until_next_LaborDay', 'Days_since_last_LaborDay',\n",
              "       'Days_until_next_Thanksgiving', 'Days_since_last_Thanksgiving'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sorted(transformed_train['DateDummy'].unique())\n",
        "transformed_train.loc[transformed_train['DateDummy'] == i,'Store']"
      ],
      "metadata": {
        "id": "SuL9hE7zRBxt",
        "outputId": "29882cc8-10cc-4a63-c481-12b601b9f797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "id": "SuL9hE7zRBxt",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122587    13\n",
              "200515    21\n",
              "390590    41\n",
              "62724      7\n",
              "128511    14\n",
              "          ..\n",
              "23316      3\n",
              "107712    11\n",
              "207276    22\n",
              "217393    23\n",
              "13362      2\n",
              "Name: Store, Length: 2977, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122587</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200515</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390590</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62724</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128511</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23316</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107712</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207276</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217393</th>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13362</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2977 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "\n",
        "class GroupMeanImputer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, group_cols=['Store', 'Dept'], target_cols=None, fallback=0):\n",
        "        self.group_cols = group_cols\n",
        "        self.target_cols = target_cols\n",
        "        self.fallback = fallback\n",
        "        self.group_means_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = X.copy()\n",
        "        if self.target_cols is None:\n",
        "            self.target_cols = X.select_dtypes(include='number').columns[\n",
        "                X.isna().any()\n",
        "            ].tolist()\n",
        "\n",
        "        self.group_means_ = (\n",
        "            X.groupby(self.group_cols)[self.target_cols]\n",
        "            .mean()\n",
        "            .reset_index()\n",
        "        )\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for col in self.target_cols:\n",
        "            # Merge group means\n",
        "            means = self.group_means_[[*self.group_cols, col]]\n",
        "            X = X.merge(means, on=self.group_cols, how='left', suffixes=('', '_group_mean'))\n",
        "\n",
        "            # Fill NaN with group mean, then fallback\n",
        "            X[col] = X[col].fillna(X[f'{col}_group_mean'])\n",
        "            X[col] = X[col].fillna(self.fallback)\n",
        "\n",
        "            # Drop helper column\n",
        "            X.drop(columns=[f'{col}_group_mean'], inplace=True)\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "VdtfmFsJJUeF"
      },
      "id": "VdtfmFsJJUeF",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "\n",
        "class LagAdder(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, val ,model ,lag_num:int = 2) -> None:\n",
        "    super().__init__()\n",
        "    self.lag_num = lag_num\n",
        "    self.model = model\n",
        "    self.y_val = val\n",
        "    self.na_imputer = GroupMeanImputer()\n",
        "    self.time = {}\n",
        "\n",
        "  def fit(self, x:pd.DataFrame, y:pd.DataFrame):\n",
        "    x_ = x.copy()\n",
        "    y_ = pd.DataFrame(y.copy())\n",
        "    y_['Store'] = x_['Store']\n",
        "    y_['DateDummy'] = x_['DateDummy']\n",
        "    y_['Dept'] = x_['Dept']\n",
        "    for i in range(1,self.lag_num+1):\n",
        "      x_[f'shift{i}'] = y_.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(i)\n",
        "\n",
        "    self.na_imputer.fit(x_)\n",
        "    x_ = self.na_imputer.transform(x_)\n",
        "    self.model.fit(x_,y)\n",
        "\n",
        "    self.time = {}\n",
        "    dates = sorted(x['DateDummy'].unique())\n",
        "    for i in dates:\n",
        "      cur_data = y_[y_['DateDummy'] == i][['Store', 'Dept','Weekly_Sales']].copy()\n",
        "      self.time[i] = cur_data\n",
        "    return self\n",
        "\n",
        "  def transform(self, x:pd.DataFrame):\n",
        "    answer = x.copy()\n",
        "    answer['WeeklySales'] = 0\n",
        "    x_ = x.copy()\n",
        "\n",
        "    dates = sorted(x['DateDummy'].unique())\n",
        "\n",
        "    time = self.time\n",
        "\n",
        "    for i in dates:\n",
        "      # print(i)\n",
        "      cur_data = x_[x_['DateDummy'] == i].copy()\n",
        "      for j in range(1,self.lag_num+1):\n",
        "        if time.get(i-j) is not None:\n",
        "          cur_data[f'shift{j}'] = cur_data.merge(time[i-j],how='left',on=['Store','Dept','DateDummy'])['Weekly_Sales']\n",
        "        else:\n",
        "          cur_data[f'shift{j}'] = np.nan\n",
        "\n",
        "      # print(len(cur_data))\n",
        "      cur_data = self.na_imputer.transform(cur_data)\n",
        "      assert cur_data.isna().sum().sum() == 0\n",
        "      # print(len(cur_data))\n",
        "      pred = self.model.predict(cur_data)\n",
        "      # print(len(answer.loc[answer['DateDummy'] == i,'WeeklySales']))\n",
        "      # print(len(pred))\n",
        "      assert len(answer.loc[answer['DateDummy'] == i,'WeeklySales'])==len(pred)\n",
        "      answer.loc[answer['DateDummy'] == i,'WeeklySales'] = pred\n",
        "      t_i = x_.loc[x_['DateDummy'] == i][['Store','Dept','DateDummy']]\n",
        "      t_i['Weekly_Sales'] = pred\n",
        "      time[i] = t_i\n",
        "\n",
        "    return answer['WeeklySales']\n",
        "\n",
        "  def predict(self, x:pd.DataFrame):\n",
        "    return self.transform(x)"
      ],
      "metadata": {
        "id": "Fr_4rm_5T3Kd"
      },
      "id": "Fr_4rm_5T3Kd",
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGboost**"
      ],
      "metadata": {
        "id": "Xx14KtxrbKt7"
      },
      "id": "Xx14KtxrbKt7"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import DMatrix\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from src.utils import wmae"
      ],
      "metadata": {
        "id": "JKEZylACbKXU"
      },
      "id": "JKEZylACbKXU",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grid search**"
      ],
      "metadata": {
        "id": "K_2BovCE0pM6"
      },
      "id": "K_2BovCE0pM6"
    },
    {
      "cell_type": "code",
      "source": [
        "from src.cross_validation import manual_model_search\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('adder', FeatureAdder()),\n",
        "    ('imputer', NaImputer()),\n",
        "    ('cat2num', Cat2Num()),\n",
        "    # ('model', XGBRegressor(\n",
        "    #     n_estimators=1000,\n",
        "    #     learning_rate=0.1,\n",
        "    #     max_depth=7,\n",
        "    #     reg_lambda=3,\n",
        "    #     min_split_loss=100,\n",
        "    #     objective='reg:squarederror',\n",
        "    #     random_state=42,\n",
        "    # ))\n",
        "  ])\n",
        "\n",
        "\n",
        "mod = Pipeline([\n",
        "    ('model', XGBRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=7,\n",
        "        reg_lambda=3,\n",
        "        min_split_loss=100,\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42,\n",
        "    ))\n",
        "  ])\n",
        "\n",
        "\n",
        "transformed_train = pipeline.fit_transform(x_train,y_train)\n",
        "transformed_val = pipeline.transform(x_val)\n",
        "\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_estimators': [200,500,800,1000],\n",
        "    'model__learning_rate': [0.1],\n",
        "    'model__max_depth': [7],\n",
        "    'model__reg_lambda': [3],\n",
        "    'model__min_split_loss': [100],\n",
        "}\n",
        "\n",
        "\n",
        "metric_kwargs = {\n",
        "    'is_holiday': transformed_val['IsHoliday']\n",
        "}\n",
        "\n",
        "best_model, best_params, best_score = manual_model_search(\n",
        "    model=mod,\n",
        "    param_grid=param_grid,\n",
        "    X_train=transformed_train,\n",
        "    y_train=y_train,\n",
        "    X_valid=transformed_val,\n",
        "    y_valid=y_val,\n",
        "    metric_func=wmae,\n",
        "    metric_kwargs=metric_kwargs\n",
        ")\n",
        "\n",
        "print(\"\\nBest Params:\", best_params)\n",
        "print(\"Best Validation Score:\", best_score)"
      ],
      "metadata": {
        "id": "hkrg3iOn5wtJ"
      },
      "id": "hkrg3iOn5wtJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "jMjbmSU70yRz"
      },
      "id": "jMjbmSU70yRz"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=7,\n",
        "        # reg_lambda=1600,\n",
        "        # min_split_loss=100,\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    # ('adder', FeatureAdder(add_dummy_date=True,start_date=pd.Timestamp('2010-02-05'))),\n",
        "    # ('imputer', NaImputer()),\n",
        "    # ('cat2num', Cat2Num()),\n",
        "    ('model', LagAdder(y_val,xgb,3))\n",
        "  ])\n",
        "\n",
        "model = pipeline.fit(transformed_train, y_train)\n",
        "\n",
        "\n",
        "y_train_predict = model.predict(transformed_train)\n",
        "y_val_predict = model.predict(transformed_val)\n",
        "\n",
        "train_score = wmae(y_train, y_train_predict,x_train['IsHoliday'].to_list())\n",
        "val_score = wmae(y_val, y_val_predict,x_val['IsHoliday'].to_list())\n",
        "print(f\"Train wmae: {train_score}, Val wmae: {val_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwAh7iMq_Nah",
        "outputId": "43f6297a-60e5-4b23-ed80-5bc639bf03b3"
      },
      "id": "BwAh7iMq_Nah",
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-180-2797298325.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[24452.754   15552.883    3307.6436  ...  2632.7996    -39.44721\n",
            " 14830.475  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  answer.loc[answer['DateDummy'] == i,'WeeklySales'] = pred\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-180-2797298325.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[  238.2762 63495.156  12973.666  ... 30741.438  24646.297  61688.03  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  answer.loc[answer['DateDummy'] == i,'WeeklySales'] = pred\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train wmae: 2393.46395790019, Val wmae: 3062.442065819097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **upload to WanDB**"
      ],
      "metadata": {
        "id": "BCBJZKD2zXIq"
      },
      "id": "BCBJZKD2zXIq"
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a185XW-zzWqO",
        "outputId": "6b12a2f4-3369-48a4-f17c-57d7d34a9310"
      },
      "id": "a185XW-zzWqO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazhgh22\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, \"xgb_pipeline.pkl\")\n",
        "wandb.init(project=\"Walmart Recruiting - Store Sales Forecasting\", name=\"xgboost:run1\")\n",
        "\n",
        "wandb.config.update({\n",
        "    'merge1' : 'train, store, how=left, on=Store',\n",
        "    'merge2' : 'train, features, how=left, on=Store, Date, IsHoliday',\n",
        "    'merged_tables' : ['train','stores','features'],\n",
        "    'time_features' : [\n",
        "        'DateDummy', 'Month', 'Year',\n",
        "        'WeekOfYear', 'Is_Christmas', 'Is_LaborDay', 'Is_Thanksgiving',\n",
        "        'Is_SuperBowl', 'Days_until_next_holiday', 'Days_since_last_holiday',\n",
        "        'week_sin', 'week_cos', 'month_sin', 'month_cos',\n",
        "        'Days_until_next_Christmas', 'Days_since_last_Christmas',\n",
        "        'Days_until_next_LaborDay', 'Days_since_last_LaborDay',\n",
        "        'Days_until_next_Thanksgiving', 'Days_since_last_Thanksgiving',\n",
        "        'Days_until_next_SuperBowl', 'Days_since_last_SuperBowl'\n",
        "    ],\n",
        "    'score_metric' : 'WMAE',\n",
        "    'score_policy' : {\n",
        "        'weight on holidays' : 5,\n",
        "        'weight on non_holidays' : 1\n",
        "    },\n",
        "    'model' : 'Xgboost',\n",
        "    'n_estimators' : 1000,\n",
        "    'learning_rate' : 0.1,\n",
        "    'max_depth' : 7,\n",
        "    'reg_lambda' : 3,\n",
        "    'min_split_loss' : 100,\n",
        "    'objective' : 'reg:squarederror',\n",
        "})\n",
        "\n",
        "wandb.log({\n",
        "    'train_wmae': train_score,\n",
        "    'val_wmae': val_score\n",
        "})\n",
        "\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    name=\"xgb_pipeline\",\n",
        "    type=\"model\",\n",
        "    description=\"XGBoost pipeline with Date engineering and imputing\"\n",
        ")\n",
        "\n",
        "artifact.add_file(\"xgb_pipeline.pkl\")\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Qxv7UN_o07mj",
        "outputId": "94c1eb31-cf24-4bdd-a933-8a569597e4ae"
      },
      "id": "Qxv7UN_o07mj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazhgh22\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Walmart-Recruiting-Store-Sales-Forecasting/wandb/run-20250702_121012-1okoh1yy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy' target=\"_blank\">xgboost:run1</a></strong> to <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_wmae</td><td>▁</td></tr><tr><td>val_wmae</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_wmae</td><td>1578.84506</td></tr><tr><td>val_wmae</td><td>2848.68957</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">xgboost:run1</strong> at: <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy</a><br> View project at: <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250702_121012-1okoh1yy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load model from wandb**"
      ],
      "metadata": {
        "id": "aVCEWJ7R3u73"
      },
      "id": "aVCEWJ7R3u73"
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import joblib\n",
        "\n",
        "# Resume or init run\n",
        "run = wandb.init(project=\"Walmart Recruiting - Store Sales Forecasting\", name=\"xgboost:run1\")\n",
        "\n",
        "# Download the artifact\n",
        "artifact = run.use_artifact('MLBeasts/Walmart Recruiting - Store Sales Forecasting/xgb_pipeline:latest', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load(f\"{artifact_dir}/xgb_pipeline.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "kmy5-BvS3xxs",
        "outputId": "e58f957a-9918-4ed6-e1cf-5806285dc644"
      },
      "id": "kmy5-BvS3xxs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Walmart-Recruiting-Store-Sales-Forecasting/wandb/run-20250702_121132-uo4s3qrj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/uo4s3qrj' target=\"_blank\">xgboost:run1</a></strong> to <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/uo4s3qrj' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/uo4s3qrj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(TEST_PATH)\n",
        "merged_test = test.merge(stores,on='Store',how='left').merge(features,how='left',on=['Store','Date','IsHoliday'])\n",
        "model.predict(merged_test)"
      ],
      "metadata": {
        "id": "htCcOh294T9C",
        "outputId": "df547d0c-d02a-491f-f0c0-d12103d1ba10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "htCcOh294T9C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33550.23    , 18070.236   , 17630.887   , ...,   887.0808  ,\n",
              "         770.0637  ,   106.878555], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}