{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azhgh22/Walmart-Recruiting-Store-Sales-Forecasting/blob/main/notebooks/general.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3e52d889",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e52d889",
        "outputId": "71a42a61-8b40-4ff2-d274-db0422d85e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "user_name = userdata.get('GITHUB_USERNAME')\n",
        "mail = userdata.get('GITHUB_MAIL')\n",
        "\n",
        "!git config --global user.name \"{user_name}\"\n",
        "!git config --global user.email \"{mail}\"\n",
        "!git clone https://{token}@github.com/azhgh22/Walmart-Recruiting-Store-Sales-Forecasting.git\n",
        "\n",
        "%cd Walmart-Recruiting-Store-Sales-Forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3cRwSz0PsGw",
        "outputId": "088a2eb4-e98d-4dd5-d584-35bdc6291a81"
      },
      "id": "u3cRwSz0PsGw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Walmart-Recruiting-Store-Sales-Forecasting'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 188 (delta 84), reused 159 (delta 64), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (188/188), 6.38 MiB | 26.23 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n",
            "/content/Walmart-Recruiting-Store-Sales-Forecasting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "!pip install -r requirements.txt\n",
        "kaggle_json_path = userdata.get('KAGGLE_JSON_PATH')\n",
        "! ./src/data_loader.sh -f {kaggle_json_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3sdpsFoP0vh",
        "outputId": "6017ae8f-52bb-457d-96f6-8d93505d4666"
      },
      "id": "K3sdpsFoP0vh",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.7.4.5)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1)\n",
            "Collecting onnx (from -r requirements.txt (line 3))\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Collecting dagshub (from -r requirements.txt (line 8))\n",
            "  Downloading dagshub-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mlflow (from -r requirements.txt (line 9))\n",
            "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (4.3.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 2)) (4.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost->-r requirements.txt (line 6)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Collecting appdirs>=1.4.4 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub->-r requirements.txt (line 8)) (0.28.1)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub->-r requirements.txt (line 8)) (13.9.4)\n",
            "Collecting dacite~=1.6.0 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub->-r requirements.txt (line 8)) (8.5.0)\n",
            "Collecting gql[requests] (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting dataclasses-json (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting treelib>=1.6.4 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading treelib-1.8.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pathvalidate>=3.0.0 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading boto3-1.39.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting semver (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting dagshub-annotation-converter>=0.1.5 (from dagshub->-r requirements.txt (line 8))\n",
            "  Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (3.1.1)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow->-r requirements.txt (line 9))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow->-r requirements.txt (line 9)) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.115.13)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.34.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 9)) (1.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub->-r requirements.txt (line 8)) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub->-r requirements.txt (line 8)) (11.2.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2)) (4.0.12)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow->-r requirements.txt (line 9)) (3.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub->-r requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r requirements.txt (line 9)) (3.2.3)\n",
            "Collecting botocore<1.40.0,>=1.39.1 (from boto3->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading botocore-1.39.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub->-r requirements.txt (line 8)) (1.20.1)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.46.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 2)) (5.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub->-r requirements.txt (line 8)) (0.1.2)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9))\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub->-r requirements.txt (line 8))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub->-r requirements.txt (line 8)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub->-r requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow->-r requirements.txt (line 9)) (0.6.1)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dagshub-0.5.10-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl (33 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading treelib-1.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading boto3-1.39.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.39.1-py3-none-any.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading gql-3.5.3-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: appdirs, treelib, semver, pathvalidate, onnx, mypy-extensions, marshmallow, jmespath, gunicorn, graphql-core, dacite, backoff, typing-inspect, opentelemetry-api, graphql-relay, gql, docker, botocore, alembic, s3transfer, opentelemetry-semantic-conventions, graphene, dataclasses-json, databricks-sdk, dagshub-annotation-converter, opentelemetry-sdk, boto3, mlflow-skinny, dagshub, mlflow\n",
            "Successfully installed alembic-1.16.2 appdirs-1.4.4 backoff-2.2.1 boto3-1.39.1 botocore-1.39.1 dacite-1.6.0 dagshub-0.5.10 dagshub-annotation-converter-0.1.10 databricks-sdk-0.57.0 dataclasses-json-0.6.7 docker-7.1.0 gql-3.5.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 marshmallow-3.26.1 mlflow-3.1.1 mlflow-skinny-3.1.1 mypy-extensions-1.1.0 onnx-1.18.0 opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 pathvalidate-3.3.1 s3transfer-0.13.0 semver-3.0.4 treelib-1.8.0 typing-inspect-0.9.0\n",
            "Setting up Kaggle credentials...\n",
            "Ensuring data directory exists at 'data/'...\n",
            "Downloading data from Kaggle for competition: 'walmart-recruiting-store-sales-forecasting'...\n",
            "Downloading walmart-recruiting-store-sales-forecasting.zip to data\n",
            "  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "100% 2.70M/2.70M [00:00<00:00, 705MB/s]\n",
            "Unzipping files...\n",
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  features.csv.zip\n",
            "  inflating: features.csv            \n",
            "Archive:  sampleSubmission.csv.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Data downloaded and extracted successfully to 'data/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "irVmks2kP-9b"
      },
      "id": "irVmks2kP-9b",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.config import *\n",
        "\n",
        "stores = pd.read_csv(STORES_PATH)\n",
        "features = pd.read_csv(FEATURES_PATH)\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "pzy0BHMtQB2U"
      },
      "id": "pzy0BHMtQB2U",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merge tables and split data**"
      ],
      "metadata": {
        "id": "RG0T-1kbUCFX"
      },
      "id": "RG0T-1kbUCFX"
    },
    {
      "cell_type": "code",
      "source": [
        "merged_train = pd.merge(train,stores,on='Store',how='left').merge(features,how='left',on=['Store','Date','IsHoliday'])"
      ],
      "metadata": {
        "id": "A2pAEl5eQDk6"
      },
      "id": "A2pAEl5eQDk6",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.time_series_split import TimeSeriesSplit\n",
        "from src.config import SPLIT_DATE\n",
        "merged_train.Date = pd.to_datetime(merged_train.Date)\n",
        "x_train, x_val = TimeSeriesSplit(SPLIT_DATE).split(merged_train)\n",
        "y_train = x_train.pop('Weekly_Sales')\n",
        "y_val = x_val.pop('Weekly_Sales')"
      ],
      "metadata": {
        "id": "HqczOQCDQ7cV"
      },
      "id": "HqczOQCDQ7cV",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Time series features**"
      ],
      "metadata": {
        "id": "OHyedVy0rS1b"
      },
      "id": "OHyedVy0rS1b"
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_engineering.time_features import FeatureAdder"
      ],
      "metadata": {
        "id": "ZukYktexrSXk"
      },
      "id": "ZukYktexrSXk",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deal with **NaN** values"
      ],
      "metadata": {
        "id": "y1BiYRuUUkAC"
      },
      "id": "y1BiYRuUUkAC"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "class NaImputer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, strategy='mean'):\n",
        "    self.strategy = strategy\n",
        "    self.imputer = SimpleImputer(strategy=strategy)\n",
        "    self.na_cols = []\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    self.na_cols = [col for col in X.columns if X[col].isna().sum() > 0]\n",
        "    self.imputer.fit(X[self.na_cols])\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    x_copy = X.copy()\n",
        "    x_copy[self.na_cols] = self.imputer.transform(x_copy[self.na_cols])\n",
        "    return x_copy"
      ],
      "metadata": {
        "id": "iSiUpzBFUAGF"
      },
      "id": "iSiUpzBFUAGF",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cat2Num**"
      ],
      "metadata": {
        "id": "6JPO12Wpm7AB"
      },
      "id": "6JPO12Wpm7AB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class Cat2Num(BaseEstimator, TransformerMixin):\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    x_copy = X.copy()\n",
        "    x_copy.pop('Date')\n",
        "    x_copy.IsHoliday = x_copy.IsHoliday.astype(int)\n",
        "    x_copy.Type = x_copy.Type.astype('category').cat.codes\n",
        "    return x_copy"
      ],
      "metadata": {
        "id": "IYLi_oCim6Mq"
      },
      "id": "IYLi_oCim6Mq",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGboost**"
      ],
      "metadata": {
        "id": "Xx14KtxrbKt7"
      },
      "id": "Xx14KtxrbKt7"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import DMatrix\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from src.utils import wmae"
      ],
      "metadata": {
        "id": "JKEZylACbKXU"
      },
      "id": "JKEZylACbKXU",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.cross_validation import manual_model_search\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('adder', FeatureAdder()),\n",
        "    ('imputer', NaImputer()),\n",
        "    ('cat2num', Cat2Num()),\n",
        "    ('model', XGBRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=7,\n",
        "        reg_lambda=3,\n",
        "        min_split_loss=100,\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42,\n",
        "    ))\n",
        "  ])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'model__n_estimators': [1000],\n",
        "    'model__learning_rate': [0.1],\n",
        "    'model__max_depth': [7],\n",
        "    'model__reg_lambda': [3],\n",
        "    'model__min_split_loss': [100],\n",
        "}\n",
        "\n",
        "\n",
        "metric_kwargs = {\n",
        "    'is_holiday': x_val['IsHoliday']\n",
        "}\n",
        "\n",
        "best_model, best_params, best_score = manual_model_search(\n",
        "    model=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    X_train=x_train,\n",
        "    y_train=y_train,\n",
        "    X_valid=x_val,\n",
        "    y_valid=y_val,\n",
        "    metric_func=wmae,\n",
        "    metric_kwargs=metric_kwargs\n",
        ")\n",
        "\n",
        "print(\"\\nBest Params:\", best_params)\n",
        "print(\"Best Validation Score:\", best_score)"
      ],
      "metadata": {
        "id": "hkrg3iOn5wtJ"
      },
      "id": "hkrg3iOn5wtJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('adder', FeatureAdder(add_dummy_date=True,start_date=pd.Timestamp('2010-02-05'))),\n",
        "    ('imputer', NaImputer()),\n",
        "    ('cat2num', Cat2Num()),\n",
        "    ('model', XGBRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=7,\n",
        "        reg_lambda=3,\n",
        "        min_split_loss=100,\n",
        "        objective='reg:squarederror',\n",
        "        random_state=42,\n",
        "    ))\n",
        "  ])\n",
        "\n",
        "model = pipeline.fit(x_train, y_train)\n",
        "\n",
        "y_train_predict = model.predict(x_train)\n",
        "y_val_predict = model.predict(x_val)\n",
        "\n",
        "train_score = wmae(y_train, y_train_predict,x_train['IsHoliday'].to_list())\n",
        "val_score = wmae(y_val, y_val_predict,x_val['IsHoliday'].to_list())\n",
        "print(f\"Train wmae: {train_score}, Val wmae: {val_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwAh7iMq_Nah",
        "outputId": "581a4032-e20a-4e05-95c5-34da29a30188"
      },
      "id": "BwAh7iMq_Nah",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train wmae: 1578.84506300633, Val wmae: 2848.6895716804747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **upload to WanDB**"
      ],
      "metadata": {
        "id": "BCBJZKD2zXIq"
      },
      "id": "BCBJZKD2zXIq"
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a185XW-zzWqO",
        "outputId": "6b12a2f4-3369-48a4-f17c-57d7d34a9310"
      },
      "id": "a185XW-zzWqO",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazhgh22\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, \"xgb_pipeline.pkl\")\n",
        "wandb.init(project=\"Walmart Recruiting - Store Sales Forecasting\", name=\"xgboost:run1\")\n",
        "\n",
        "wandb.config.update({\n",
        "    'merge1' : 'train, store, how=left, on=Store',\n",
        "    'merge2' : 'train, features, how=left, on=Store, Date, IsHoliday',\n",
        "    'merged_tables' : ['train','stores','features'],\n",
        "    'time_features' : [\n",
        "        'DateDummy', 'Month', 'Year',\n",
        "        'WeekOfYear', 'Is_Christmas', 'Is_LaborDay', 'Is_Thanksgiving',\n",
        "        'Is_SuperBowl', 'Days_until_next_holiday', 'Days_since_last_holiday',\n",
        "        'week_sin', 'week_cos', 'month_sin', 'month_cos',\n",
        "        'Days_until_next_Christmas', 'Days_since_last_Christmas',\n",
        "        'Days_until_next_LaborDay', 'Days_since_last_LaborDay',\n",
        "        'Days_until_next_Thanksgiving', 'Days_since_last_Thanksgiving',\n",
        "        'Days_until_next_SuperBowl', 'Days_since_last_SuperBowl'\n",
        "    ],\n",
        "    'score_metric' : 'WMAE',\n",
        "    'score_policy' : {\n",
        "        'weight on holidays' : 5,\n",
        "        'weight on non_holidays' : 1\n",
        "    },\n",
        "    'model' : 'Xgboost',\n",
        "    'n_estimators' : 1000,\n",
        "    'learning_rate' : 0.1,\n",
        "    'max_depth' : 7,\n",
        "    'reg_lambda' : 3,\n",
        "    'min_split_loss' : 100,\n",
        "    'objective' : 'reg:squarederror',\n",
        "})\n",
        "\n",
        "wandb.log({\n",
        "    'train_wmae': train_score,\n",
        "    'val_wmae': val_score\n",
        "})\n",
        "\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    name=\"xgb_pipeline\",\n",
        "    type=\"model\",\n",
        "    description=\"XGBoost pipeline with Date engineering and imputing\"\n",
        ")\n",
        "\n",
        "artifact.add_file(\"xgb_pipeline.pkl\")\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Qxv7UN_o07mj",
        "outputId": "94c1eb31-cf24-4bdd-a933-8a569597e4ae"
      },
      "id": "Qxv7UN_o07mj",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mazhgh22\u001b[0m (\u001b[33mMLBeasts\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Walmart-Recruiting-Store-Sales-Forecasting/wandb/run-20250702_121012-1okoh1yy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy' target=\"_blank\">xgboost:run1</a></strong> to <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_wmae</td><td>▁</td></tr><tr><td>val_wmae</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_wmae</td><td>1578.84506</td></tr><tr><td>val_wmae</td><td>2848.68957</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">xgboost:run1</strong> at: <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/1okoh1yy</a><br> View project at: <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250702_121012-1okoh1yy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load model from wandb**"
      ],
      "metadata": {
        "id": "aVCEWJ7R3u73"
      },
      "id": "aVCEWJ7R3u73"
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import joblib\n",
        "\n",
        "# Resume or init run\n",
        "run = wandb.init(project=\"Walmart Recruiting - Store Sales Forecasting\", name=\"xgboost:run1\")\n",
        "\n",
        "# Download the artifact\n",
        "artifact = run.use_artifact('MLBeasts/Walmart Recruiting - Store Sales Forecasting/xgb_pipeline:latest', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load(f\"{artifact_dir}/xgb_pipeline.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "kmy5-BvS3xxs",
        "outputId": "e58f957a-9918-4ed6-e1cf-5806285dc644"
      },
      "id": "kmy5-BvS3xxs",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Walmart-Recruiting-Store-Sales-Forecasting/wandb/run-20250702_121132-uo4s3qrj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/uo4s3qrj' target=\"_blank\">xgboost:run1</a></strong> to <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/uo4s3qrj' target=\"_blank\">https://wandb.ai/MLBeasts/Walmart%20Recruiting%20-%20Store%20Sales%20Forecasting/runs/uo4s3qrj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(TEST_PATH)\n",
        "merged_test = test.merge(stores,on='Store',how='left').merge(features,how='left',on=['Store','Date','IsHoliday'])\n",
        "model.predict(merged_test)"
      ],
      "metadata": {
        "id": "htCcOh294T9C",
        "outputId": "df547d0c-d02a-491f-f0c0-d12103d1ba10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "htCcOh294T9C",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33550.23    , 18070.236   , 17630.887   , ...,   887.0808  ,\n",
              "         770.0637  ,   106.878555], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}